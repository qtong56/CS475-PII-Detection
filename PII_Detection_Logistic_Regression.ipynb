{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Model: Logistic Regression with SpaCy tokenization and CountVectorizer\n"
      ],
      "metadata": {
        "id": "3zoA9A8SoAgj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading and Preprocessing"
      ],
      "metadata": {
        "id": "Xu776CkepD-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip pii-detection-removal-from-educational-data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qP3Z4uoH00IZ",
        "outputId": "a792db0f-8469-4b50-be28-bb0ef6523839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  pii-detection-removal-from-educational-data.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.json               \n",
            "  inflating: train.json              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data\n",
        "with open('train.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Convert data to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display data structure\n",
        "print(df.head())\n",
        "\n",
        "# Extract token and label lists from the data\n",
        "def extract_tokens_labels(data):\n",
        "    tokens = []\n",
        "    labels = []\n",
        "    for entry in data:\n",
        "        tokens.extend(entry['tokens'])\n",
        "        labels.extend(entry['labels'])\n",
        "    return tokens, labels\n",
        "\n",
        "tokens, labels = extract_tokens_labels(data)\n",
        "\n",
        "# Split data into training and validation sets\n",
        "tokens_train, tokens_val, labels_train, labels_val = train_test_split(\n",
        "    tokens, labels, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oM_BuLioLgn",
        "outputId": "d7842511-fb14-4bf5-c7e9-6b51c4e3bd44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   document                                          full_text  \\\n",
            "0         7  Design Thinking for innovation reflexion-Avril...   \n",
            "1        10  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...   \n",
            "2        16  Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...   \n",
            "3        20  Design Thinking for Innovation\\n\\nSindy Samaca...   \n",
            "4        56  Assignment:  Visualization Reflection  Submitt...   \n",
            "\n",
            "                                              tokens  \\\n",
            "0  [Design, Thinking, for, innovation, reflexion,...   \n",
            "1  [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n",
            "2  [Reporting, process, \\n\\n, by, Gilberto, Gambo...   \n",
            "3  [Design, Thinking, for, Innovation, \\n\\n, Sind...   \n",
            "4  [Assignment, :,   , Visualization,  , Reflecti...   \n",
            "\n",
            "                                 trailing_whitespace  \\\n",
            "0  [True, True, True, True, False, False, True, F...   \n",
            "1  [True, False, False, True, True, False, False,...   \n",
            "2  [True, False, False, True, True, False, False,...   \n",
            "3  [True, True, True, False, False, True, False, ...   \n",
            "4  [False, False, False, False, False, False, Fal...   \n",
            "\n",
            "                                              labels  \n",
            "0  [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...  \n",
            "1  [B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...  \n",
            "2  [O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...  \n",
            "3  [O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...  \n",
            "4  [O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SpaCy for Tokenization"
      ],
      "metadata": {
        "id": "PI9Pyi4TpGDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Assuming `tokens_train` and `tokens_val` are lists of tokens from the training and validation splits\n",
        "vectorizer = CountVectorizer(tokenizer=lambda x: x, lowercase=False, stop_words=None)\n",
        "X_train = vectorizer.fit_transform(tokens_train)\n",
        "X_val = vectorizer.transform(tokens_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRqlzndvo8x4",
        "outputId": "0bdb3ab1-b5a7-41d8-c580-581eb7fe67ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "FvrrZEXIpIIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import fbeta_score\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(labels_train)\n",
        "y_val = label_encoder.transform(labels_val)\n",
        "\n",
        "# Train a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "7JOIVRslpKKx",
        "outputId": "86b12027-5e7a-4cc6-874a-d26627b7405c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "7LNcI4DAt7SZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check unique labels in training and validation sets\n",
        "unique_train_labels = set(y_train)\n",
        "unique_val_labels = set(y_val)\n",
        "\n",
        "print(\"Unique labels in training set:\", unique_train_labels)\n",
        "print(\"Unique labels in validation set:\", unique_val_labels)\n",
        "\n",
        "# Check the number of labels and their names\n",
        "print(\"Number of labels:\", len(label_encoder.classes_))\n",
        "print(\"Label names:\", label_encoder.classes_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7ddsQ33wPuV",
        "outputId": "723e4c35-b784-4af9-d49d-5951eeefa8d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique labels in training set: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
            "Unique labels in validation set: {0, 1, 2, 3, 5, 6, 8, 9, 10, 12}\n",
            "Number of labels: 13\n",
            "Label names: ['B-EMAIL' 'B-ID_NUM' 'B-NAME_STUDENT' 'B-PHONE_NUM' 'B-STREET_ADDRESS'\n",
            " 'B-URL_PERSONAL' 'B-USERNAME' 'I-ID_NUM' 'I-NAME_STUDENT' 'I-PHONE_NUM'\n",
            " 'I-STREET_ADDRESS' 'I-URL_PERSONAL' 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Predict on validation set\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# All possible label IDs (as numerical IDs)\n",
        "all_label_ids = range(len(label_encoder.classes_))\n",
        "\n",
        "# Corresponding names for all labels\n",
        "target_names = [label_encoder.inverse_transform([label_id])[0] for label_id in all_label_ids]\n",
        "\n",
        "# Now print the classification report with all labels specified\n",
        "print(classification_report(y_val, y_pred, labels=all_label_ids, target_names=target_names))\n",
        "\n",
        "fbeta = fbeta_score(y_val, y_pred, beta=5, average='micro')\n",
        "print(f\"F-beta score with beta=5: {fbeta}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgrF5PfNs6er",
        "outputId": "83a70408-2311-44cd-ab95-2d7a402c7185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  precision    recall  f1-score   support\n",
            "\n",
            "         B-EMAIL       0.80      1.00      0.89         8\n",
            "        B-ID_NUM       0.94      0.88      0.91        17\n",
            "  B-NAME_STUDENT       0.00      0.00      0.00       267\n",
            "     B-PHONE_NUM       0.00      0.00      0.00         1\n",
            "B-STREET_ADDRESS       0.00      0.00      0.00         0\n",
            "  B-URL_PERSONAL       0.59      0.56      0.57        18\n",
            "      B-USERNAME       0.00      0.00      0.00         2\n",
            "        I-ID_NUM       0.00      0.00      0.00         0\n",
            "  I-NAME_STUDENT       0.00      0.00      0.00       218\n",
            "     I-PHONE_NUM       0.00      0.00      0.00         2\n",
            "I-STREET_ADDRESS       0.00      0.00      0.00         3\n",
            "  I-URL_PERSONAL       0.00      0.00      0.00         0\n",
            "               O       1.00      1.00      1.00    997971\n",
            "\n",
            "       micro avg       1.00      1.00      1.00    998507\n",
            "       macro avg       0.26      0.26      0.26    998507\n",
            "    weighted avg       1.00      1.00      1.00    998507\n",
            "\n",
            "F-beta score with beta=5: 0.9994672045363728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Check where predictions are wrong\n",
        "errors = np.where(y_val != y_pred)[0]\n",
        "print(\"Sample misclassifications:\")\n",
        "for error in errors[:10]:  # show first 10 errors\n",
        "    print(f\"Token: {tokens_val[error]}, True: {label_encoder.inverse_transform([y_val[error]])}, Pred: {label_encoder.inverse_transform([y_pred[error]])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pehMeQcVs8x8",
        "outputId": "16f4ec5f-4841-4b82-8ced-332766b322a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample misclassifications:\n",
            "Token: Narayn, True: ['I-NAME_STUDENT'], Pred: ['O']\n",
            "Token: Sarah, True: ['B-NAME_STUDENT'], Pred: ['O']\n",
            "Token: Willian, True: ['B-NAME_STUDENT'], Pred: ['O']\n",
            "Token: Monica, True: ['B-NAME_STUDENT'], Pred: ['O']\n",
            "Token: Ahmed, True: ['B-NAME_STUDENT'], Pred: ['O']\n",
            "Token: https://www.changemakers.com/youthventure/resources/rootcause, True: ['O'], Pred: ['B-URL_PERSONAL']\n",
            "Token: Luis, True: ['B-NAME_STUDENT'], Pred: ['O']\n",
            "Token: IV-8322, True: ['B-ID_NUM'], Pred: ['O']\n",
            "Token: Aakash, True: ['B-NAME_STUDENT'], Pred: ['O']\n",
            "Token: Richter, True: ['I-NAME_STUDENT'], Pred: ['O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Part 2\n",
        "The previous evaluation is a useless evaluation, because it looks at all the ones without O's. Let's now check the evaluation considering only labels that are not 'O'."
      ],
      "metadata": {
        "id": "ngoU5zgi1KNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Convert label IDs back to their string representations\n",
        "labels_true = label_encoder.inverse_transform(y_val)\n",
        "labels_pred = label_encoder.inverse_transform(y_pred)\n",
        "\n",
        "# Filter out 'O' labels to focus on PII relevant predictions\n",
        "non_o_mask = labels_true != 'O'\n",
        "non_o_true = labels_true[non_o_mask]\n",
        "non_o_pred = labels_pred[non_o_mask]\n",
        "\n",
        "# Calculate the accuracy for non-O labels\n",
        "non_o_accuracy = accuracy_score(non_o_true, non_o_pred)\n",
        "print(f\"Accuracy for non-'O' labels: {non_o_accuracy}\")\n",
        "\n",
        "# Generate and print classification report for non-O labels\n",
        "print(classification_report(non_o_true, non_o_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIpyhM-nxhvm",
        "outputId": "6dc10b7f-56c5-4aae-969f-d3a8ca96e464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for non-'O' labels: 0.061567164179104475\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "         B-EMAIL       1.00      1.00      1.00         8\n",
            "        B-ID_NUM       0.94      0.88      0.91        17\n",
            "  B-NAME_STUDENT       0.00      0.00      0.00       267\n",
            "     B-PHONE_NUM       0.00      0.00      0.00         1\n",
            "  B-URL_PERSONAL       1.00      0.56      0.71        18\n",
            "      B-USERNAME       0.00      0.00      0.00         2\n",
            "  I-NAME_STUDENT       0.00      0.00      0.00       218\n",
            "     I-PHONE_NUM       0.00      0.00      0.00         2\n",
            "I-STREET_ADDRESS       0.00      0.00      0.00         3\n",
            "               O       0.00      0.00      0.00         0\n",
            "\n",
            "        accuracy                           0.06       536\n",
            "       macro avg       0.29      0.24      0.26       536\n",
            "    weighted avg       0.08      0.06      0.07       536\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}