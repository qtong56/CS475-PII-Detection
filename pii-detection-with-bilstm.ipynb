{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":66653,"databundleVersionId":7500999,"sourceType":"competition"},{"sourceId":7659420,"sourceType":"datasetVersion","datasetId":4459964}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CS 475/675 Machine Learning: Project\n## Goals:\n### 4.1 Must accomplish\n- Implement a robust data preprocessing pipeline to handle tokenization, feature extraction, and label encoding.\n- Develop and train a machine learning model capable of accurately detecting PII types in student essays, achieving a competitive score on the evaluation metric.\n- Generate predictions for the test set essays and submit them in the required format for evaluation.\n\n### 4.2 Expect to accomplish\n- Fine-tune the model architecture and hyperparameters to optimize performance on the provided training data.\n- Conduct error analysis and model interpretation to identify common misclassifications and areas for improvement.\n- Investigate the use of external datasets or pre-trained language models to enhance the model’s generalization capabilities.\n\n### 4.3 Would like to accomplish\n- Implement ensemble learning techniques, such as model averaging or stacking, to combine multiple base models and further boost detection accuracy and robustness.\n- Investigate methods for handling imbalance class distributions, particularly for rare PII types.\n- Develop visualization tools and techniques to facilitate the interpretation of model predictions.\n","metadata":{}},{"cell_type":"markdown","source":"# BiLSTM","metadata":{}},{"cell_type":"code","source":"!pip install wurlitzer","metadata":{"execution":{"iopub.status.busy":"2024-04-29T23:54:32.830914Z","iopub.execute_input":"2024-04-29T23:54:32.831527Z","iopub.status.idle":"2024-04-29T23:54:46.658994Z","shell.execute_reply.started":"2024-04-29T23:54:32.831483Z","shell.execute_reply":"2024-04-29T23:54:46.657918Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting wurlitzer\n  Downloading wurlitzer-3.1.0-py3-none-any.whl.metadata (2.5 kB)\nDownloading wurlitzer-3.1.0-py3-none-any.whl (8.4 kB)\nInstalling collected packages: wurlitzer\nSuccessfully installed wurlitzer-3.1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install gensim","metadata":{"execution":{"iopub.status.busy":"2024-04-29T23:54:46.661221Z","iopub.execute_input":"2024-04-29T23:54:46.661761Z","iopub.status.idle":"2024-04-29T23:54:59.128728Z","shell.execute_reply.started":"2024-04-29T23:54:46.661724Z","shell.execute_reply":"2024-04-29T23:54:59.127570Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: gensim in /opt/conda/lib/python3.10/site-packages (4.3.2)\nRequirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.10/site-packages (from gensim) (1.26.4)\nRequirement already satisfied: scipy>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from gensim) (1.11.4)\nRequirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from gensim) (6.4.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install keras tensorflow matplotlib","metadata":{"execution":{"iopub.status.busy":"2024-04-29T23:54:59.130405Z","iopub.execute_input":"2024-04-29T23:54:59.130816Z","iopub.status.idle":"2024-04-29T23:55:14.948708Z","shell.execute_reply.started":"2024-04-29T23:54:59.130773Z","shell.execute_reply":"2024-04-29T23:55:14.947684Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (3.0.5)\nRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.5)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras) (1.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras) (1.26.4)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras) (13.7.0)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras) (0.0.7)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras) (3.10.0)\nRequirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from keras) (0.1.8)\nRequirement already satisfied: ml-dtypes in /opt/conda/lib/python3.10/site-packages (from keras) (0.2.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.51.1)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nCollecting keras\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (2.17.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\nDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 3.0.5\n    Uninstalling keras-3.0.5:\n      Successfully uninstalled keras-3.0.5\nSuccessfully installed keras-2.15.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install git+https://www.github.com/keras-team/keras-contrib.git","metadata":{"execution":{"iopub.status.busy":"2024-04-29T23:55:14.951028Z","iopub.execute_input":"2024-04-29T23:55:14.951335Z","iopub.status.idle":"2024-04-29T23:55:31.442743Z","shell.execute_reply.started":"2024-04-29T23:55:14.951304Z","shell.execute_reply":"2024-04-29T23:55:31.441635Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting git+https://www.github.com/keras-team/keras-contrib.git\n  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-sm_1cz5z\n  Running command git clone --filter=blob:none --quiet https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-sm_1cz5z\n  warning: redirecting to https://github.com/keras-team/keras-contrib.git/\n  Resolved https://www.github.com/keras-team/keras-contrib.git to commit 3fc5ef709e061416f4bc8a92ca3750c824b5d2b0\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (from keras_contrib==2.0.8) (2.15.0)\nBuilding wheels for collected packages: keras_contrib\n  Building wheel for keras_contrib (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for keras_contrib: filename=keras_contrib-2.0.8-py3-none-any.whl size=101060 sha256=3077b9cfb85f2d4b2c4921d446c2bbb02ad5b59cc231563d692cea2af9d43bda\n  Stored in directory: /tmp/pip-ephem-wheel-cache-qfl2rel2/wheels/74/d5/f7/0245af7ac33d5b0c2e095688649916e4bf9a8d6b3362a849f5\nSuccessfully built keras_contrib\nInstalling collected packages: keras_contrib\nSuccessfully installed keras_contrib-2.0.8\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, precision_score, recall_score, f1_score\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.utils import to_categorical\nfrom keras.models import Model\nfrom keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\nfrom keras_contrib.layers import CRF\nfrom keras_contrib.losses import crf_loss\nfrom keras_contrib.metrics import crf_viterbi_accuracy\nfrom keras.callbacks import ModelCheckpoint\n","metadata":{"execution":{"iopub.status.busy":"2024-04-29T23:58:32.738369Z","iopub.execute_input":"2024-04-29T23:58:32.739240Z","iopub.status.idle":"2024-04-29T23:58:32.745962Z","shell.execute_reply.started":"2024-04-29T23:58:32.739206Z","shell.execute_reply":"2024-04-29T23:58:32.744829Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Data Loading and Preprocessing","metadata":{}},{"cell_type":"code","source":"import json\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Load data\nwith open(\"/kaggle/input/pii-detection-removal-from-educational-data/train.json\", \"r\") as file:\n    data = json.load(file)\n\n# Data extraction: Keeping tokens and labels grouped by documents\ndocuments = [{'tokens': entry['tokens'], 'labels': entry['labels']} for entry in data]\n\n# Split data into training and validation sets\ntrain_docs, val_docs = train_test_split(documents, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T23:57:39.924658Z","iopub.execute_input":"2024-04-29T23:57:39.925056Z","iopub.status.idle":"2024-04-29T23:57:42.658458Z","shell.execute_reply.started":"2024-04-29T23:57:39.925025Z","shell.execute_reply":"2024-04-29T23:57:42.657648Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def extract_tokens_and_labels(docs):\n    tokens = [doc['tokens'] for doc in docs]\n    labels = [doc['labels'] for doc in docs]\n    return tokens, labels\n\ntrain_tokens, train_labels = extract_tokens_and_labels(train_docs)\nval_tokens, val_labels = extract_tokens_and_labels(val_docs)\n\n# Create label and token index mappings\nlabel2idx = {\n    'O': 0, 'B-NAME_STUDENT': 1, 'I-NAME_STUDENT': 2, 'B-EMAIL': 3, 'I-EMAIL': 4,\n    'B-USERNAME': 5, 'I-USERNAME': 6, 'B-ID_NUM': 7, 'I-ID_NUM': 8,\n    'B-PHONE_NUM': 9, 'I-PHONE_NUM': 10, 'B-URL_PERSONAL': 11, 'I-URL_PERSONAL': 12,\n    'B-STREET_ADDRESS': 13, 'I-STREET_ADDRESS': 14\n}\ntoken2idx = {token: idx for idx, token in enumerate(set(token for doc in train_tokens + val_tokens for token in doc))}","metadata":{"execution":{"iopub.status.busy":"2024-04-29T23:57:49.517461Z","iopub.execute_input":"2024-04-29T23:57:49.517817Z","iopub.status.idle":"2024-04-29T23:57:50.085327Z","shell.execute_reply.started":"2024-04-29T23:57:49.517791Z","shell.execute_reply":"2024-04-29T23:57:50.084284Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Feature Extraction","metadata":{}},{"cell_type":"code","source":"# Convert tokens and labels to integer indices\ntrain_tokens_idx = [[token2idx.get(token, 0) for token in doc] for doc in train_tokens]\nval_tokens_idx = [[token2idx.get(token, 0) for token in doc] for doc in val_tokens]\ntrain_labels_idx = [[label2idx[label] for label in labels] for labels in train_labels]\nval_labels_idx = [[label2idx[label] for label in labels] for labels in val_labels]\n\n# Pad token and label sequences\nmax_len = max(len(seq) for seq in train_tokens_idx + val_tokens_idx)\ntrain_tokens_padded = pad_sequences(train_tokens_idx, maxlen=max_len, padding='post')\nval_tokens_padded = pad_sequences(val_tokens_idx, maxlen=max_len, padding='post')\ntrain_labels_padded = pad_sequences(train_labels_idx, maxlen=max_len, padding='post', value=label2idx['O'])\nval_labels_padded = pad_sequences(val_labels_idx, maxlen=max_len, padding='post', value=label2idx['O'])\n\n# Convert labels to one-hot encoding\nnum_labels = len(label2idx)\ntrain_labels_onehot = to_categorical(train_labels_padded, num_classes=num_labels)\nval_labels_onehot = to_categorical(val_labels_padded, num_classes=num_labels)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T23:57:52.243788Z","iopub.execute_input":"2024-04-29T23:57:52.244188Z","iopub.status.idle":"2024-04-29T23:57:55.330339Z","shell.execute_reply.started":"2024-04-29T23:57:52.244161Z","shell.execute_reply":"2024-04-29T23:57:55.329530Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Convert tokens to integers\ntrain_tokens_idx = [[token2idx.get(token, 0) for token in doc] for doc in train_tokens]\nval_tokens_idx = [[token2idx.get(token, 0) for token in doc] for doc in val_tokens]\n\n# Pad token sequences and label sequences\nmax_len = max(len(seq) for seq in train_tokens_idx + val_tokens_idx)\ntrain_tokens_padded = pad_sequences(train_tokens_idx, maxlen=max_len, padding='post')\nval_tokens_padded = pad_sequences(val_tokens_idx, maxlen=max_len, padding='post')\ntrain_labels_padded = pad_sequences(train_labels_idx, maxlen=max_len, padding='post')\nval_labels_padded = pad_sequences(val_labels_idx, maxlen=max_len, padding='post')\n\n# Convert labels to one-hot encoding\nnum_labels = len(label2idx)\ntrain_labels_onehot = to_categorical(train_labels_padded, num_classes=num_labels)\nval_labels_onehot = to_categorical(val_labels_padded, num_classes=num_labels)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T23:57:57.775346Z","iopub.execute_input":"2024-04-29T23:57:57.775753Z","iopub.status.idle":"2024-04-29T23:58:00.570718Z","shell.execute_reply.started":"2024-04-29T23:57:57.775723Z","shell.execute_reply":"2024-04-29T23:58:00.569818Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"# Model architecture\nembedding_dim = 100\nlstm_units = 64\ndropout_rate = 0.5\n\ninput_layer = tf.keras.layers.Input(shape=(max_len,))\nembedding_layer = tf.keras.layers.Embedding(len(token2idx), embedding_dim, mask_zero=True)(input_layer)\nbilstm_layer = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_units, return_sequences=True))(embedding_layer)\ndropout_layer = tf.keras.layers.Dropout(dropout_rate)(bilstm_layer)\ndense_layer = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(num_labels, activation='softmax'))(dropout_layer)\n\nmodel = tf.keras.Model(inputs=input_layer, outputs=dense_layer)\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nepochs = 10\nbatch_size = 32\nmodel.fit(train_tokens_padded, train_labels_onehot,\n          validation_data=(val_tokens_padded, val_labels_onehot),\n          epochs=epochs, batch_size=batch_size,\n          callbacks=[ModelCheckpoint('best_model.h5.keras', save_best_only=True, monitor='val_accuracy', mode='max')])","metadata":{"execution":{"iopub.status.busy":"2024-04-30T00:14:58.312249Z","iopub.execute_input":"2024-04-30T00:14:58.312657Z","iopub.status.idle":"2024-04-30T00:22:32.338249Z","shell.execute_reply.started":"2024-04-30T00:14:58.312629Z","shell.execute_reply":"2024-04-30T00:22:32.337271Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Epoch 1/10\n171/171 [==============================] - 69s 351ms/step - loss: 0.1954 - accuracy: 0.9909 - val_loss: 0.0049 - val_accuracy: 0.9994\nEpoch 2/10\n171/171 [==============================] - 52s 303ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 0.0045 - val_accuracy: 0.9994\nEpoch 3/10\n171/171 [==============================] - 46s 268ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 0.0042 - val_accuracy: 0.9994\nEpoch 4/10\n171/171 [==============================] - 44s 261ms/step - loss: 0.0043 - accuracy: 0.9995 - val_loss: 0.0039 - val_accuracy: 0.9994\nEpoch 5/10\n171/171 [==============================] - 41s 239ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.0033 - val_accuracy: 0.9994\nEpoch 6/10\n171/171 [==============================] - 39s 227ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0029 - val_accuracy: 0.9994\nEpoch 7/10\n171/171 [==============================] - 38s 219ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0029 - val_accuracy: 0.9995\nEpoch 8/10\n171/171 [==============================] - 39s 227ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0030 - val_accuracy: 0.9995\nEpoch 9/10\n171/171 [==============================] - 35s 204ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0031 - val_accuracy: 0.9995\nEpoch 10/10\n171/171 [==============================] - 35s 202ms/step - loss: 9.9364e-04 - accuracy: 0.9997 - val_loss: 0.0033 - val_accuracy: 0.9995\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7e295ed67a90>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n\n# Predict on validation data\npredictions = model.predict(val_tokens_padded)\npredicted_labels = np.argmax(predictions, axis=-1)  # Convert probabilities to class labels\n\n# Flatten the predictions and true labels for evaluation\ny_pred_flat = predicted_labels.flatten()\ny_val_flat = val_labels_padded.flatten()\n\n# Mapping index to label for better readability in reports\nidx2label = {v: k for k, v in label2idx.items()}\n\n# Convert indices to labels\ny_pred_labels = [idx2label[idx] for idx in y_pred_flat]\ny_true_labels = [idx2label[idx] for idx in y_val_flat]\n\n# Generate a classification report\nprint(classification_report(y_true_labels, y_pred_labels, labels=list(label2idx.keys()), target_names=list(label2idx.keys()), zero_division=1))\n\nnon_o_labels = [label for label in label2idx if label != 'O']\nnon_o_indices = [label2idx[label] for label in non_o_labels]\n\n# Filtering out 'O' labels from flat lists\nnon_o_true_labels = [label for label in y_true_labels if label in non_o_labels]\nnon_o_pred_labels = [y_pred_labels[i] for i, label in enumerate(y_true_labels) if label in non_o_labels]\n\nprecision = precision_score(non_o_true_labels, non_o_pred_labels, labels=non_o_labels, average='weighted', zero_division=1)\nrecall = recall_score(non_o_true_labels, non_o_pred_labels, labels=non_o_labels, average='weighted', zero_division=1)\nf1 = f1_score(non_o_true_labels, non_o_pred_labels, labels=non_o_labels, average='weighted', zero_division=1)\n\nprint(f\"Precision for Non-'O' labels: {precision}\")\nprint(f\"Recall for Non-'O' labels: {recall}\")\nprint(f\"F1-score for Non-'O' labels: {f1}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-30T00:22:32.340251Z","iopub.execute_input":"2024-04-30T00:22:32.340569Z","iopub.status.idle":"2024-04-30T00:24:36.790917Z","shell.execute_reply.started":"2024-04-30T00:22:32.340543Z","shell.execute_reply":"2024-04-30T00:24:36.789738Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"43/43 [==============================] - 4s 44ms/step\n                  precision    recall  f1-score   support\n\n               O       1.00      1.00      1.00   4491312\n  B-NAME_STUDENT       0.41      0.19      0.26       263\n  I-NAME_STUDENT       0.57      0.18      0.27       244\n         B-EMAIL       1.00      0.00      0.00         3\n         I-EMAIL       1.00      1.00      1.00         0\n      B-USERNAME       1.00      1.00      1.00         0\n      I-USERNAME       1.00      1.00      1.00         0\n        B-ID_NUM       1.00      0.00      0.00        10\n        I-ID_NUM       1.00      1.00      1.00         0\n     B-PHONE_NUM       1.00      0.00      0.00         2\n     I-PHONE_NUM       1.00      0.00      0.00         3\n  B-URL_PERSONAL       1.00      0.00      0.00        28\n  I-URL_PERSONAL       1.00      1.00      1.00         0\nB-STREET_ADDRESS       1.00      0.00      0.00         1\nI-STREET_ADDRESS       1.00      0.00      0.00        10\n\n       micro avg       1.00      1.00      1.00   4491876\n       macro avg       0.93      0.42      0.44   4491876\n    weighted avg       1.00      1.00      1.00   4491876\n\nPrecision for Non-'O' labels: 0.7000953398619323\nRecall for Non-'O' labels: 0.16666666666666666\nF1-score for Non-'O' labels: 0.2607713523005846\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, fbeta_score\n\nbeta = 5\nf_beta = fbeta_score(non_o_true_labels, non_o_pred_labels, labels=non_o_labels, average='weighted', beta=beta, zero_division=1)\n\nprint(f\"F-beta score for Non-'O' labels (beta={beta}): {f_beta}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-30T00:24:56.809199Z","iopub.execute_input":"2024-04-30T00:24:56.809971Z","iopub.status.idle":"2024-04-30T00:24:56.824143Z","shell.execute_reply.started":"2024-04-30T00:24:56.809938Z","shell.execute_reply":"2024-04-30T00:24:56.823164Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"F-beta score for Non-'O' labels (beta=5): 0.17142525033402833\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Error Analysis and Explainability","metadata":{}},{"cell_type":"code","source":"y_pred_flat = np.argmax(predictions, axis=-1).flatten()  # predictions is the output of model.predict\ny_val_flat = val_labels_padded.flatten()  # val_labels_padded is already defined in your pre-processing\n\n# Convert numeric labels back to string labels\ny_pred_labels_flat = [idx2label[idx] for idx in y_pred_flat]\ny_true_labels_flat = [idx2label[idx] for idx in y_val_flat]\n\n# Extract tokens and labels for the validation set\ntokens_val = [doc['tokens'] for doc in val_docs]  # Assuming val_docs is available\nlabels_val = [doc['labels'] for doc in val_docs]\n\n# Flatten these for direct comparisons\ntokens_val_flat = [token for sublist in tokens_val for token in sublist]\nlabels_val_flat = [label for sublist in labels_val for label in sublist]\n\n\n# Find indices where predictions and true values differ\nmismatches = [i for i, (y_pred, y_true) in enumerate(zip(y_pred_labels_flat, y_true_labels_flat)) if y_pred != y_true]\n\nfrom collections import Counter\n\n# Analyze types of errors\nerror_types = Counter((y_true, y_pred) for y_true, y_pred in zip(y_true_labels_flat, y_pred_labels_flat) if y_true != y_pred)\nprint(\"Common error types:\")\nfor (true_label, pred_label), count in error_types.most_common(10):\n    print(f\"True: {true_label}, Predicted: {pred_label}, Count: {count}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-30T00:28:54.944142Z","iopub.execute_input":"2024-04-30T00:28:54.944574Z","iopub.status.idle":"2024-04-30T00:29:09.938860Z","shell.execute_reply.started":"2024-04-30T00:28:54.944541Z","shell.execute_reply":"2024-04-30T00:29:09.937912Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Common error types:\nTrue: B-NAME_STUDENT, Predicted: O, Count: 191\nTrue: I-NAME_STUDENT, Predicted: O, Count: 178\nTrue: O, Predicted: B-NAME_STUDENT, Count: 49\nTrue: B-URL_PERSONAL, Predicted: O, Count: 28\nTrue: I-NAME_STUDENT, Predicted: B-NAME_STUDENT, Count: 23\nTrue: B-NAME_STUDENT, Predicted: I-NAME_STUDENT, Count: 21\nTrue: B-ID_NUM, Predicted: O, Count: 10\nTrue: O, Predicted: I-NAME_STUDENT, Count: 8\nTrue: I-STREET_ADDRESS, Predicted: O, Count: 7\nTrue: I-STREET_ADDRESS, Predicted: I-NAME_STUDENT, Count: 3\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}